{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LKVan/Lab2_ML/blob/van/Lab_5_20130462_LeKhanhVan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to deal with **SVM** to classification tasks and compare its performance with other competitive algorithms. In general, **SVM** is one of the most popular and widely used supervised machine learning algorithms.\n",
        "\n",
        "*   **Deadline: 23:59, 17/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd '/content/gdrive/MyDrive/ML_Lab5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZ5Wy_L5FtMh",
        "outputId": "eee1070a-9e51-498e-953d-bb3a957093b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/ML_Lab5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from prettytable import PrettyTable\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "For breast cancer dataset (https://tinyurl.com/3vme8hr3) which could be loaded from datasets in sklearn as follows:\n",
        "\n",
        "```\n",
        "#Import scikit-learn dataset library\n",
        "from sklearn import datasets\n",
        "\n",
        "#Load dataset\n",
        "cancer = datasets.load_breast_cancer()\n",
        "```\n",
        "\n",
        "*   1.1.\tApply SVM algorithm to above dataset using linear kernel.\n",
        "*   1.2.\tCompare the obtained results with other competitive algorithms (Logistic Regression, Decision Tree, kNN) based on metrics: accuracy, precision, recall, f1 measures.\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "cancer = datasets.load_breast_cancer()\n",
        "X1 = cancer.data\n",
        "y1 = cancer.target\n",
        "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1,y1, test_size=0.3, train_size=0.7,\n",
        "random_state=None, shuffle=True, stratify=None)"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.1\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(x_train1,y_train1)\n",
        "y_pred1 = clf.predict(x_test1)\n",
        "cm = confusion_matrix(y_test1,y_pred1)\n",
        "print(cm)\n",
        "ConfusionMatrixDisplay.from_predictions(y_test1, y_pred1)\n",
        "\n",
        "accuracy1 = round(metrics.accuracy_score(y_test1,y_pred1),4)\n",
        "precision1 = round(metrics.precision_score(y_test1,y_pred1,average='macro'),4)\n",
        "recall1 = round(metrics.recall_score(y_test1,y_pred1,average='macro'),4)\n",
        "f11 = round(metrics.f1_score(y_test1,y_pred1,average='macro'),4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "77q1CVpzKojP",
        "outputId": "436dbc31-27cb-47d8-ce96-6009d320773b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 57   3]\n",
            " [  4 107]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.2\n",
        "# Logistic Regression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(x_train1, y_train1)\n",
        "\n",
        "y_pred2 = classifier.predict(x_test1)\n",
        "\n",
        "accuracy2 = round(metrics.accuracy_score(y_test1,y_pred2),4)\n",
        "precision2 = round(metrics.precision_score(y_test1,y_pred2,average='macro'),4)\n",
        "recall2 = round(metrics.recall_score(y_test1,y_pred2,average='macro'),4)\n",
        "f12 = round(metrics.f1_score(y_test1,y_pred2,average='macro'),4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHGAzMvNMCwv",
        "outputId": "22f3d5bf-dee5-45e3-cd24-0feb7e146f91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# kNN\n",
        "kNN = KNeighborsClassifier(n_neighbors= 3)\n",
        "kNN.fit(x_train1,y_train1)\n",
        "y_pred3 = kNN.predict(x_test1)\n",
        "\n",
        "accuracy3 = round(metrics.accuracy_score(y_test1,y_pred3),4)\n",
        "precision3 = round(metrics.precision_score(y_test1,y_pred3,average='macro'),4)\n",
        "recall3 = round(metrics.recall_score(y_test1,y_pred3,average='macro'),4)\n",
        "f13 = round(metrics.f1_score(y_test1,y_pred3,average='macro'),4)\n"
      ],
      "metadata": {
        "id": "1Ngax4GdNZVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Decision tree\n",
        "clf_model = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5)\n",
        "clf_model.fit(x_train1,y_train1)\n",
        "\n",
        "y_pred4 = clf_model.predict(x_test1)\n",
        "\n",
        "accuracy4 = round(metrics.accuracy_score(y_test1,y_pred4),4)\n",
        "precision4 = round(metrics.precision_score(y_test1,y_pred4,average='macro'),4)\n",
        "recall4 = round(metrics.recall_score(y_test1,y_pred4,average='macro'),4)\n",
        "f14 = round(metrics.f1_score(y_test1,y_pred4,average='macro'),4)\n"
      ],
      "metadata": {
        "id": "S-b2P2T5NyOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretty table\n",
        "t = PrettyTable(['Name', 'Accuraty','Precision','Recall','F1'])\n",
        "t.add_row(['SVM', accuracy1,precision1,recall1,f11])\n",
        "t.add_row(['Logictis Registion', accuracy2,precision2,recall2,f12])\n",
        "t.add_row(['kNN', accuracy3,precision3,recall3,f13])\n",
        "t.add_row(['Decision Tree', accuracy4,precision4,recall1,f14])\n",
        "print(t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXh0G96eOEBH",
        "outputId": "24e0590b-bc93-4e2a-88f6-0ec6a0b95160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+-----------+--------+--------+\n",
            "|        Name        | Accuraty | Precision | Recall |   F1   |\n",
            "+--------------------+----------+-----------+--------+--------+\n",
            "|        SVM         |  0.9591  |   0.9536  | 0.957  | 0.9552 |\n",
            "| Logictis Registion |  0.9474  |   0.9385  | 0.948  | 0.9429 |\n",
            "|        kNN         |  0.9123  |   0.9026  | 0.9056 | 0.9041 |\n",
            "|   Decision Tree    |  0.9357  |   0.9382  | 0.957  | 0.9279 |\n",
            "+--------------------+----------+-----------+--------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "\n",
        "*   1.1.\tPerform SVM algorithm to **Iris dataset** using **linear kernel**.\n",
        "*   1.2.\tCompare the obtained results in 1.1 with SVM using other kernels (**Polynomial Kernel, Gaussian Kernel, Sigmoid Kernel, Radial Basis Function Kernel**). Some metrics could be used: accuracy, precision, recall, f1 measures\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "iris = datasets.load_iris()\n",
        "X2 = iris.data\n",
        "y2 = iris.target\n",
        "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2,y2, test_size=0.3, train_size=0.7,\n",
        "random_state=None, shuffle=True, stratify=None)"
      ],
      "metadata": {
        "id": "_xhPpF5b033h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.1\n",
        "linear = svm.SVC(kernel='linear')\n",
        "linear.fit(x_train2,y_train2)\n",
        "y_pred_linear = linear.predict(x_test2)\n",
        "\n",
        "print(confusion_matrix(y_test2,y_pred_linear))\n",
        "print(classification_report(y_test2,y_pred_linear))\n",
        "\n",
        "accuracy_linear = round(metrics.accuracy_score(y_test2,y_pred_linear),4)\n",
        "precision_linear = round(metrics.precision_score(y_test2,y_pred_linear,average='macro'),4)\n",
        "recall_linear = round(metrics.recall_score(y_test2,y_pred_linear,average='macro'),4)\n",
        "f1_linear = round(metrics.f1_score(y_test2,y_pred_linear,average='macro'),4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3z7SqB4QZUf",
        "outputId": "e991fd8b-c0a7-42aa-e439-741088eb8fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[12  0  0]\n",
            " [ 0 14  1]\n",
            " [ 0  0 18]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        12\n",
            "           1       1.00      0.93      0.97        15\n",
            "           2       0.95      1.00      0.97        18\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.98      0.98        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.2\n",
        "# Polynomial Kernel\n",
        "poly = svm.SVC(kernel='poly', degree=3, gamma='scale', coef0=0.0)\n",
        "poly.fit(x_train2,y_train2)\n",
        "y_pred_poly = poly.predict(x_test2)\n",
        "\n",
        "accuracy_poly = round(metrics.accuracy_score(y_test2,y_pred_poly),4)\n",
        "precision_poly = round(metrics.precision_score(y_test2,y_pred_poly,average='macro'),4)\n",
        "recall_poly = round(metrics.recall_score(y_test2,y_pred_poly,average='macro'),4)\n",
        "f1_poly = round(metrics.f1_score(y_test2,y_pred_poly,average='macro'),4)"
      ],
      "metadata": {
        "id": "6gAlA0o6R6Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rbf\n",
        "rbf = svm.SVC(kernel='rbf', gamma='scale')\n",
        "rbf.fit(x_train2,y_train2)\n",
        "y_pred_rbf = rbf.predict(x_test2)\n",
        "\n",
        "accuracy_rbf = round(metrics.accuracy_score(y_test2,y_pred_rbf),4)\n",
        "precision_rbf = round(metrics.precision_score(y_test2,y_pred_rbf,average='macro'),4)\n",
        "recall_rbf = round(metrics.recall_score(y_test2,y_pred_rbf,average='macro'),4)\n",
        "f1_rbf = round(metrics.f1_score(y_test2,y_pred_rbf,average='macro'),4)"
      ],
      "metadata": {
        "id": "4eOIKSe0WVlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sigmoid\n",
        "sigmoid = svm.SVC(kernel='sigmoid',degree=3, coef0=0.0)\n",
        "sigmoid.fit(x_train2,y_train2)\n",
        "y_pred_sigmoid = sigmoid.predict(x_test2)\n",
        "# print(classification_report(y_test2,y_pred_sigmoid))\n",
        "\n",
        "accuracy_sigmoid = round(metrics.accuracy_score(y_test2,y_pred_sigmoid),4)\n",
        "precision_sigmoid = round(metrics.precision_score(y_test2,y_pred_sigmoid,average='macro'),4)\n",
        "recall_sigmoid = round(metrics.recall_score(y_test2,y_pred_sigmoid,average='macro'),4)\n",
        "f1_sigmoid = round(metrics.f1_score(y_test2,y_pred_sigmoid,average='macro'),4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0rK9UNMY67G",
        "outputId": "b41c358c-6a7b-49a0-9316-246c566a5cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pretty table\n",
        "t2 = PrettyTable(['Algorithms', 'Accuraty','Precision','Recall','F1'])\n",
        "t2.add_row(['Linear', accuracy_linear,precision_linear,recall_linear,f1_linear])\n",
        "t2.add_row(['Poly', accuracy_poly,precision_poly,recall_poly,f1_poly])\n",
        "t2.add_row(['Sigmoid', accuracy_sigmoid,precision_sigmoid,recall_sigmoid,f1_sigmoid])\n",
        "t2.add_row(['RBF', accuracy_rbf,precision_rbf,recall_rbf,f1_rbf])\n",
        "print(t2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbpc3L3faa4d",
        "outputId": "1b59e8d6-ff47-415a-a296-b9ae1c98dd38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+-----------+--------+--------+\n",
            "| Algorithms | Accuraty | Precision | Recall |   F1   |\n",
            "+------------+----------+-----------+--------+--------+\n",
            "|   Linear   |  0.9778  |   0.9825  | 0.9778 | 0.9795 |\n",
            "|    Poly    |  0.9556  |   0.9667  | 0.9556 | 0.9586 |\n",
            "|  Sigmoid   |  0.2667  |   0.0889  | 0.3333 | 0.1404 |\n",
            "|    RBF     |  0.9556  |   0.9667  | 0.9556 | 0.9586 |\n",
            "+------------+----------+-----------+--------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with mnist dataset based on accuracy, precision, recall, f1 measures.\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X3 = mnist.data\n",
        "Y3 = mnist.target\n",
        "\n",
        "x_train3, x_test3, y_train3, y_test3 = train_test_split(X3,Y3, test_size=0.3, train_size=0.7,\n",
        "random_state=None, shuffle=True, stratify=None)"
      ],
      "metadata": {
        "id": "QPc7453hcUEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "classifier = LogisticRegression(random_state = 0)\n",
        "classifier.fit(x_train3, y_train3)\n",
        "\n",
        "y_pred_logictis = classifier.predict(x_test3)\n",
        "\n",
        "accuracy_logictis = round(metrics.accuracy_score(y_test3,y_pred_logictis),4)\n",
        "precision_logictis = round(metrics.precision_score(y_test3,y_pred_logictis,average='macro'),4)\n",
        "recall_logictis = round(metrics.recall_score(y_test3,y_pred_logictis,average='macro'),4)\n",
        "f1_logictis = round(metrics.f1_score(y_test3,y_pred_logictis,average='macro'),4)\n",
        "\n",
        "# kNN\n",
        "kNN = KNeighborsClassifier(n_neighbors= 3)\n",
        "kNN.fit(x_train3,y_train3)\n",
        "y_pred_kNN = kNN.predict(x_test3)\n",
        "\n",
        "accuracy_kNN = round(metrics.accuracy_score(y_test3,y_pred_kNN),4)\n",
        "precision_kNN = round(metrics.precision_score(y_test3,y_pred_kNN,average='macro'),4)\n",
        "recall_kNN = round(metrics.recall_score(y_test3,y_pred_kNN,average='macro'),4)\n",
        "f1_kNN = round(metrics.f1_score(y_test3,y_pred_kNN,average='macro'),4)\n",
        "\n",
        "# Decision tree\n",
        "clf_model = DecisionTreeClassifier(criterion=\"gini\", random_state=42,\n",
        "max_depth=3, min_samples_leaf=5)\n",
        "clf_model.fit(x_train3,y_train3)\n",
        "\n",
        "y_pred_decision = clf_model.predict(x_test3)\n",
        "\n",
        "accuracy_decision = round(metrics.accuracy_score(y_test3,y_pred_decision),4)\n",
        "precision_decision = round(metrics.precision_score(y_test3,y_pred_decision,average='macro'),4)\n",
        "recall_decision = round(metrics.recall_score(y_test3,y_pred_decision,average='macro'),4)\n",
        "f1_decision = round(metrics.f1_score(y_test3,y_pred_decision,average='macro'),4)"
      ],
      "metadata": {
        "id": "x9lMFDQtdCAF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd30c85f-a621-43ee-a9dd-b1e7099d192a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# linear\n",
        "linear = svm.SVC(kernel='linear')\n",
        "linear.fit(x_train3,y_train3)\n",
        "y_pred_linear = linear.predict(x_test3)\n",
        "\n",
        "accuracy_linear = round(metrics.accuracy_score(y_test3,y_pred_linear),4)\n",
        "precision_linear = round(metrics.precision_score(y_test3,y_pred_linear,average='macro'),4)\n",
        "recall_linear = round(metrics.recall_score(y_test3,y_pred_linear,average='macro'),4)\n",
        "f1_linear = round(metrics.f1_score(y_test3,y_pred_linear,average='macro'),4)\n",
        "\n",
        "# Polynomial Kernel\n",
        "poly = svm.SVC(kernel='poly', degree=3, gamma='scale', coef0=0.0)\n",
        "poly.fit(x_train3,y_train3)\n",
        "y_pred_poly = poly.predict(x_test3)\n",
        "\n",
        "accuracy_poly = round(metrics.accuracy_score(y_test3,y_pred_poly),4)\n",
        "precision_poly = round(metrics.precision_score(y_test3,y_pred_poly,average='macro'),4)\n",
        "recall_poly = round(metrics.recall_score(y_test3,y_pred_poly,average='macro'),4)\n",
        "f1_poly = round(metrics.f1_score(y_test3,y_pred_poly,average='macro'),4)\n",
        "\n",
        "# rbf\n",
        "rbf = svm.SVC(kernel='rbf', gamma='scale')\n",
        "rbf.fit(x_train3,y_train3)\n",
        "y_pred_rbf = rbf.predict(x_test3)\n",
        "\n",
        "accuracy_rbf = round(metrics.accuracy_score(y_test3,y_pred_rbf),4)\n",
        "precision_rbf = round(metrics.precision_score(y_test3,y_pred_rbf,average='macro'),4)\n",
        "recall_rbf = round(metrics.recall_score(y_test3,y_pred_rbf,average='macro'),4)\n",
        "f1_rbf = round(metrics.f1_score(y_test3,y_pred_rbf,average='macro'),4)\n",
        "\n",
        "# sigmoid\n",
        "sigmoid = svm.SVC(kernel='sigmoid',degree=3, coef0=0.0)\n",
        "sigmoid.fit(x_train3,y_train3)\n",
        "y_pred_sigmoid = sigmoid.predict(x_test3)\n",
        "\n",
        "accuracy_sigmoid = round(metrics.accuracy_score(y_test3,y_pred_sigmoid),4)\n",
        "precision_sigmoid = round(metrics.precision_score(y_test3,y_pred_sigmoid,average='macro'),4)\n",
        "recall_sigmoid = round(metrics.recall_score(y_test3,y_pred_sigmoid,average='macro'),4)\n",
        "f1_sigmoid = round(metrics.f1_score(y_test3,y_pred_sigmoid,average='macro'),4)"
      ],
      "metadata": {
        "id": "-ZpH9ZqLPNGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretty table\n",
        "t3 = PrettyTable(['Algorithms', 'Accuraty','Precision','Recall','F1'])\n",
        "t3.add_row(['Logictis Regresion',accuracy_logictis,precision_logictis,recall_logictis,f1_logictis])\n",
        "t3.add_row(['kNN',accuracy_kNN,precision_kNN,recall_kNN,f1_kNN])\n",
        "t3.add_row(['Decision Tree',accuracy_decision,precision_decision,recall_decision,f1_decision])\n",
        "t3.add_row(['Linear', accuracy_linear,precision_linear,recall_linear,f1_linear])\n",
        "t3.add_row(['Poly', accuracy_poly,precision_poly,recall_poly,f1_poly])\n",
        "t3.add_row(['Sigmoid', accuracy_sigmoid,precision_sigmoid,recall_sigmoid,f1_sigmoid])\n",
        "t3.add_row(['RBF', accuracy_rbf,precision_rbf,recall_rbf,f1_rbf])\n",
        "print(t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCpIBCYPP8nn",
        "outputId": "35768a23-780b-4055-bdf1-f02c12a8c092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+-----------+--------+--------+\n",
            "|     Algorithms     | Accuraty | Precision | Recall |   F1   |\n",
            "+--------------------+----------+-----------+--------+--------+\n",
            "| Logictis Regresion |  0.9519  |   0.9527  | 0.953  | 0.9522 |\n",
            "|        kNN         |  0.9926  |   0.9924  | 0.9929 | 0.9926 |\n",
            "|   Decision Tree    |  0.4519  |   0.3947  | 0.4746 | 0.3801 |\n",
            "|       Linear       |  0.9759  |   0.976   | 0.976  | 0.9757 |\n",
            "|        Poly        |  0.9889  |   0.9888  | 0.989  | 0.9888 |\n",
            "|      Sigmoid       |  0.9056  |   0.9081  | 0.9061 | 0.9061 |\n",
            "|        RBF         |  0.9926  |   0.9927  | 0.9925 | 0.9926 |\n",
            "+--------------------+----------+-----------+--------+--------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Compare the performance of selected classification algorithms (Decision Tree, kNN, Logistic Regression) and SVM (using different kernels) with **credit card dataset** based on accuracy, precision, recall, f1 measures.\n",
        "\n",
        "*   Give some comments on the obtained results\n",
        "*   Identify issues with dataset, and propose the solutions to these issues\n",
        "\n"
      ],
      "metadata": {
        "id": "Z5pp7_h-aP2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "creditcard = pd.read_csv('creditcard.csv')\n",
        "creditcard"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "b7a0d145-d784-4ce8-ab70-ad165e23911d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
              "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
              "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
              "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
              "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
              "...          ...        ...        ...       ...       ...       ...   \n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
              "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
              "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
              "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
              "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
              "...          ...       ...       ...       ...       ...       ...     ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "0           0  \n",
              "1           0  \n",
              "2           0  \n",
              "3           0  \n",
              "4           0  \n",
              "...       ...  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[284807 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c1bb23b-c259-47b4-ba51-005205041005\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284807 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c1bb23b-c259-47b4-ba51-005205041005')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c1bb23b-c259-47b4-ba51-005205041005 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c1bb23b-c259-47b4-ba51-005205041005');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}